---
title: Weighting Lifting Exercise prediction
  analysis
output:
  html_document:
    keep_md: yes
---

```{r message=FALSE}
library(caret)
library(gbm)
library(dplyr)
library(tidyverse)
```

## Data Loading
The data in this report comes from http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. We start off by downloading the training and testing datasets into R.

```{r}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="pml-testing.csv")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

## Data Cleanup
The original data is organized in a way that there are some measurement lines, followed by a summary line. The summary line contains a lot of NA / DIV!0 values with the measurements, and is denoted in the data by the new_window = 'yes' variable. Here we filter them out as summary is simply transformation of measurement statistics, and would be expected to be highly-correlated with them. Besides, we take out the independent variables used in our model.

```{r}
set.seed(12345)
training_clean <- training %>% filter(new_window == 'no') %>% select(starts_with("gyros"), starts_with("accel"), starts_with("magnet"), starts_with("classe")) 
```

## Model Fitting
We will begin by fitting the data to 3 models, random forest, boosting and linear discriminant analysis, applying them to the training dataset. As can be seen below, random forest attained the highest level of accuracy (100%) with a tight 95% confidence interval (0.9998, 1). This is much better than the estimation from boosting and linear discriminant analysis models. 
As a reference, we also printed out the times so you may compare the relative time taken to build to models.

```{r}
Sys.time()
mod1 <- train(classe ~ ., method="rf", data=training_clean)
Sys.time()
mod2 <- train(classe ~ ., method="gbm", data=training_clean, verbose=FALSE)
Sys.time()
mod3 <- train(classe ~ ., method="lda", data=training_clean)
Sys.time()

pred1 <- predict(mod1, training_clean)
pred2 <- predict(mod2, training_clean)
pred3 <- predict(mod3, training_clean)

confusionMatrix(as.factor(training_clean$classe), pred1)
confusionMatrix(as.factor(training_clean$classe), pred2)
confusionMatrix(as.factor(training_clean$classe), pred3)
```

## Model Testing
Finally, we apply the selected model to the testing dataset. 

```{r}
predict(mod1, testing)
```
